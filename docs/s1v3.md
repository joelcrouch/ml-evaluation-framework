# Sprint 1: Database Schema & Core Infrastructure - Living Document

> **Sprint Duration**: 2 Weeks  
> **Status**: ‚úÖ **COMPLETED**  
> **Completion**: 100% (48/48 tasks complete)  
> **Sprint Goal**: Establish PostgreSQL database, create universal schema with JSONB, implement ORM models with user-first philosophy, and build CRUD operations

[‚Üê Back to Project Dashboard](project-status-dashboard.md)

---

## üìä Sprint Overview

**Start Date**: [Your Start Date]  
**End Date**: [Your End Date]  
**Sprint Lead**: [Your Name]

### Sprint Objectives ‚úÖ
By the end of this sprint, we have:
1. ‚úÖ PostgreSQL database running with universal schema (JSONB)
2. ‚úÖ All tables created (test_cases, model_runs, responses, evaluations)
3. ‚úÖ SQLAlchemy ORM models for all entities (TestCase, ModelRun, Response, Evaluation)
4. ‚úÖ Alembic migration system configured and working
5. ‚úÖ CRUD operations for all tables with user-first defaults
6. ‚úÖ Test data seeding scripts demonstrating multi-domain capability

---

## üéØ Sprint Goals & Success Metrics

### Primary Goals ‚úÖ
- [x] **G1**: Universal database schema fully implemented and tested
- [x] **G2**: Can insert 1000 test cases in <5 seconds
- [x] **G3**: Foreign key relationships work correctly with CASCADE
- [x] **G4**: CRUD operations have 90%+ test coverage

### Success Metrics ‚úÖ
- ‚úÖ All tables created successfully with JSONB support
- ‚úÖ Can query responses with associated test cases in <100ms
- ‚úÖ Alembic migrations work bidirectionally (up/down)
- ‚úÖ Connection pooling handles 50+ concurrent connections
- ‚úÖ Seed data script populates realistic multi-domain test data

---

## üìã Detailed Task Breakdown

### 1. Environment Setup ‚úÖ (5/5 tasks complete)

#### 1.1 Repository & Project Structure ‚úÖ

**Status**: ‚úÖ COMPLETED  
**Estimated Hours**: 2h  
**Actual Hours**: [Your actual time]

**Tasks Completed**:
- [x] **T1.1.1**: Created GitHub repository
- [x] **T1.1.2**: Set up Python virtual environment (Python 3.9+)
- [x] **T1.1.3**: Created project directory structure
- [x] **T1.1.4**: Initialized git with .gitignore
- [x] **T1.1.5**: Created README with setup instructions

**Final Directory Structure**:
```
ml-evaluation-framework/
‚îú‚îÄ‚îÄ ml_eval/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ database/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ models.py         # ORM models (TestCase, ModelRun, etc.)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ connection.py     # DB connection with pooling
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ crud.py           # CRUD operations (user-first)
‚îÇ   ‚îú‚îÄ‚îÄ test_suite/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ query_engine/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ evaluators/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ __init__.py
‚îÇ   ‚îî‚îÄ‚îÄ reporting/
‚îÇ       ‚îî‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ migrations/                # Alembic migrations
‚îÇ   ‚îú‚îÄ‚îÄ versions/
‚îÇ   ‚îú‚îÄ‚îÄ env.py
‚îÇ   ‚îî‚îÄ‚îÄ script.py.mako
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ test_database/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_models.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_crud.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test_connection.py
‚îÇ   ‚îî‚îÄ‚îÄ conftest.py
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ seed_user_data.py     # Multi-domain seed data
‚îÇ   ‚îî‚îÄ‚îÄ schema.sql            # SQL schema (reference)
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îî‚îÄ‚îÄ database.yaml
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ alembic.ini
‚îú‚îÄ‚îÄ setup.py
‚îú‚îÄ‚îÄ .env
‚îú‚îÄ‚îÄ .env.example
‚îú‚îÄ‚îÄ .gitignore
‚îî‚îÄ‚îÄ README.md
```

---

#### 1.2 Dependencies Installation ‚úÖ

**Status**: ‚úÖ COMPLETED  
**Estimated Hours**: 3h  
**Actual Hours**: [Your actual time]

**Tasks Completed**:
- [x] **T1.2.1**: Created requirements.txt
- [x] **T1.2.2**: Installed PostgreSQL locally (v14+)
- [x] **T1.2.3**: Installed Python dependencies
- [x] **T1.2.4**: Set up .env file with database credentials
- [x] **T1.2.5**: Tested database connection

**Final requirements.txt**:
```txt
# Database
sqlalchemy>=2.0.0
psycopg2-binary>=2.9.0
alembic>=1.12.0

# Data handling
pandas>=1.5.0
numpy>=1.21.0

# Configuration
python-dotenv>=1.0.0
pyyaml>=6.0

# CLI
click>=8.0.0

# Testing
pytest>=7.0.0
pytest-cov>=4.0.0
factory-boy>=3.2.0

# Utilities
tqdm>=4.60.0
```

**Final .env configuration**:
```bash
# Database Configuration
DB_HOST=localhost
DB_PORT=5432
DB_NAME=ml_eval_db
DB_USER=ml_eval_user
DB_PASSWORD=[your_secure_password]

# Connection Pool
DB_POOL_SIZE=10
DB_MAX_OVERFLOW=20
DB_ECHO=false
```

---

### 2. Universal Database Schema Design ‚úÖ (8/8 tasks complete)

#### 2.1 Schema SQL Creation ‚úÖ

**Status**: ‚úÖ COMPLETED  
**Estimated Hours**: 6h  
**Actual Hours**: [Your actual time]

**Tasks Completed**:
- [x] **T2.1.1**: Designed complete universal schema diagram
- [x] **T2.1.2**: Wrote SQL for test_cases table (CRITICAL: universal schema)
- [x] **T2.1.3**: Wrote SQL for model_runs table
- [x] **T2.1.4**: Wrote SQL for responses table
- [x] **T2.1.5**: Wrote SQL for evaluations table
- [x] **T2.1.6**: Defined foreign key constraints with CASCADE
- [x] **T2.1.7**: Created performance indexes (including GIN on JSONB)
- [x] **T2.1.8**: Wrote `scripts/schema.sql` (reference implementation)

**Final Universal Schema** (`scripts/schema.sql`):

```sql
-- Drop existing tables (for clean setup)
DROP TABLE IF EXISTS evaluations CASCADE;
DROP TABLE IF EXISTS responses CASCADE;
DROP TABLE IF EXISTS model_runs CASCADE;
DROP TABLE IF EXISTS test_cases CASCADE;

-- =============================================================================
-- TEST CASES TABLE (UNIVERSAL SCHEMA - USER FIRST)
-- =============================================================================
CREATE TABLE test_cases (
    id SERIAL PRIMARY KEY,
    
    -- Flexible input storage (JSONB)
    input_data JSONB NOT NULL,
    input_type VARCHAR(50) NOT NULL,  -- 'text', 'image_path', 'tabular', 'audio_path', etc.
    input_format VARCHAR(50),          -- 'json', 'base64', 'url', 'file_path', etc.
    
    -- Expected output (JSONB)
    ground_truth JSONB NOT NULL,
    output_type VARCHAR(50) NOT NULL,  -- 'classification', 'text', 'regression', 'bounding_boxes', etc.
    
    -- Organization
    model_type VARCHAR(100),           -- 'computer_vision', 'nlp', 'time_series', 'recommender', etc.
    category VARCHAR(100),
    tags TEXT[],
    difficulty VARCHAR(50),
    
    -- USER-FIRST PHILOSOPHY (CRITICAL)
    origin VARCHAR(50) DEFAULT 'human',      -- 'human' (default) vs 'ai-generated'
    is_verified BOOLEAN DEFAULT TRUE,        -- Assumes user data is trusted
    
    -- Metadata
    metadata JSONB DEFAULT '{}',
    created_by VARCHAR(255),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
    -- Constraints
    CONSTRAINT check_input_not_empty CHECK (input_data IS NOT NULL),
    CONSTRAINT check_ground_truth_not_empty CHECK (ground_truth IS NOT NULL),
    CONSTRAINT check_origin CHECK (origin IN ('human', 'ai-generated'))
);

-- =============================================================================
-- MODEL RUNS TABLE
-- =============================================================================
CREATE TABLE model_runs (
    id SERIAL PRIMARY KEY,
    model_name VARCHAR(255) NOT NULL,
    model_version VARCHAR(100) NOT NULL,
    model_type VARCHAR(100) NOT NULL,  -- 'computer_vision', 'nlp', 'time_series', etc.
    model_endpoint TEXT,                -- API URL or local path
    config JSONB DEFAULT '{}',          -- Model-specific configuration (flexible)
    status VARCHAR(50) NOT NULL DEFAULT 'pending',
    started_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    completed_at TIMESTAMP,
    total_cases INTEGER DEFAULT 0,
    completed_cases INTEGER DEFAULT 0,
    failed_cases INTEGER DEFAULT 0,
    
    -- Constraints
    CONSTRAINT check_status CHECK (status IN ('pending', 'running', 'completed', 'failed', 'cancelled')),
    CONSTRAINT check_cases_positive CHECK (
        total_cases >= 0 AND 
        completed_cases >= 0 AND 
        failed_cases >= 0
    ),
    CONSTRAINT check_cases_sum CHECK (completed_cases + failed_cases <= total_cases)
);

-- =============================================================================
-- RESPONSES TABLE (UNIVERSAL OUTPUT STORAGE)
-- =============================================================================
CREATE TABLE responses (
    id SERIAL PRIMARY KEY,
    run_id INTEGER NOT NULL REFERENCES model_runs(id) ON DELETE CASCADE,
    test_case_id INTEGER NOT NULL REFERENCES test_cases(id) ON DELETE CASCADE,
    
    -- Flexible output storage (JSONB)
    output_data JSONB NOT NULL,
    
    -- Performance metrics
    latency_ms INTEGER,
    memory_mb FLOAT,
    tokens_used INTEGER,               -- For LLMs
    
    -- Error handling
    error_message TEXT,
    
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
    -- Constraints
    CONSTRAINT unique_run_test_case UNIQUE(run_id, test_case_id),
    CONSTRAINT check_latency_positive CHECK (latency_ms IS NULL OR latency_ms >= 0),
    CONSTRAINT check_memory_positive CHECK (memory_mb IS NULL OR memory_mb >= 0),
    CONSTRAINT check_tokens_positive CHECK (tokens_used IS NULL OR tokens_used >= 0)
);

-- =============================================================================
-- EVALUATIONS TABLE
-- =============================================================================
CREATE TABLE evaluations (
    id SERIAL PRIMARY KEY,
    response_id INTEGER NOT NULL REFERENCES responses(id) ON DELETE CASCADE,
    evaluator_type VARCHAR(100) NOT NULL,
    score FLOAT NOT NULL,
    passed BOOLEAN NOT NULL,
    metrics JSONB DEFAULT '{}',        -- Task-specific metrics
    feedback TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
    -- Constraints
    CONSTRAINT check_score_range CHECK (score >= 0 AND score <= 1),
    CONSTRAINT unique_response_evaluator UNIQUE(response_id, evaluator_type)
);

-- =============================================================================
-- PERFORMANCE INDEXES
-- =============================================================================

-- Standard B-tree indexes
CREATE INDEX idx_responses_run_id ON responses(run_id);
CREATE INDEX idx_responses_test_case_id ON responses(test_case_id);
CREATE INDEX idx_evaluations_response_id ON evaluations(response_id);
CREATE INDEX idx_test_cases_category ON test_cases(category);
CREATE INDEX idx_test_cases_model_type ON test_cases(model_type);
CREATE INDEX idx_test_cases_origin ON test_cases(origin);
CREATE INDEX idx_model_runs_status ON model_runs(status);
CREATE INDEX idx_model_runs_type ON model_runs(model_type);
CREATE INDEX idx_model_runs_name_version ON model_runs(model_name, model_version);

-- GIN indexes for JSONB columns (enables fast JSON queries)
CREATE INDEX idx_test_cases_input_data_gin ON test_cases USING GIN (input_data);
CREATE INDEX idx_test_cases_ground_truth_gin ON test_cases USING GIN (ground_truth);
CREATE INDEX idx_test_cases_metadata_gin ON test_cases USING GIN (metadata);
CREATE INDEX idx_responses_output_data_gin ON responses USING GIN (output_data);
CREATE INDEX idx_evaluations_metrics_gin ON evaluations USING GIN (metrics);
CREATE INDEX idx_model_runs_config_gin ON model_runs USING GIN (config);

-- =============================================================================
-- TRIGGERS FOR AUTO-UPDATE TIMESTAMPS
-- =============================================================================

CREATE OR REPLACE FUNCTION update_updated_at_column()
RETURNS TRIGGER AS $$
BEGIN
    NEW.updated_at = CURRENT_TIMESTAMP;
    RETURN NEW;
END;
$$ language 'plpgsql';

CREATE TRIGGER update_test_cases_updated_at 
    BEFORE UPDATE ON test_cases 
    FOR EACH ROW 
    EXECUTE FUNCTION update_updated_at_column();

-- =============================================================================
-- COMMENTS FOR DOCUMENTATION
-- =============================================================================

COMMENT ON TABLE test_cases IS 'Universal test cases supporting all ML domains (CV, NLP, Time Series, etc.)';
COMMENT ON COLUMN test_cases.input_data IS 'Flexible JSONB storage for any input type';
COMMENT ON COLUMN test_cases.ground_truth IS 'Expected output in flexible JSONB format';
COMMENT ON COLUMN test_cases.origin IS 'User-first: human (default) vs ai-generated';
COMMENT ON COLUMN test_cases.is_verified IS 'Assumes user-submitted data is verified truth';

COMMENT ON TABLE model_runs IS 'Tracks evaluation runs for model versions';
COMMENT ON TABLE responses IS 'Model outputs stored in flexible JSONB format';
COMMENT ON TABLE evaluations IS 'Assessment results comparing outputs to ground truth';
```

**Key Design Decisions**:
1. ‚úÖ `test_cases` (NOT `test_prompts`) - universal naming
2. ‚úÖ JSONB for all flexible data (input_data, ground_truth, output_data)
3. ‚úÖ `origin` field with DEFAULT 'human' - user-first philosophy
4. ‚úÖ `is_verified` field with DEFAULT TRUE - trust user data
5. ‚úÖ GIN indexes on all JSONB columns for fast queries
6. ‚úÖ Comprehensive foreign keys with CASCADE for data integrity

---

### 3. SQLAlchemy ORM Models ‚úÖ (10/10 tasks complete)

#### 3.1 Base Model Setup ‚úÖ

**Status**: ‚úÖ COMPLETED  
**Estimated Hours**: 4h  
**Actual Hours**: [Your actual time]

**Tasks Completed**:
- [x] **T3.1.1**: Created database connection module
- [x] **T3.1.2**: Set up SQLAlchemy Base
- [x] **T3.1.3**: Configured connection pooling (QueuePool)
- [x] **T3.1.4**: Added session management
- [x] **T3.1.5**: Created context manager for transactions

**Final Code** (`ml_eval/database/connection.py`):

```python
"""Database connection and session management."""

import os
from contextlib import contextmanager
from typing import Generator

from dotenv import load_dotenv
from sqlalchemy import create_engine, event
from sqlalchemy.engine import Engine
from sqlalchemy.orm import declarative_base, sessionmaker, Session
from sqlalchemy.pool import QueuePool

# Load environment variables
load_dotenv()

# Database configuration
DB_HOST = os.getenv("DB_HOST", "localhost")
DB_PORT = os.getenv("DB_PORT", "5432")
DB_NAME = os.getenv("DB_NAME", "ml_eval_db")
DB_USER = os.getenv("DB_USER", "ml_eval_user")
DB_PASSWORD = os.getenv("DB_PASSWORD")

# Connection string
DATABASE_URL = f"postgresql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}"

# Create engine with connection pooling
engine = create_engine(
    DATABASE_URL,
    poolclass=QueuePool,
    pool_size=int(os.getenv("DB_POOL_SIZE", 10)),
    max_overflow=int(os.getenv("DB_MAX_OVERFLOW", 20)),
    pool_pre_ping=True,  # Verify connections before using
    echo=os.getenv("DB_ECHO", "false").lower() == "true",  # SQL logging
)

# Create session factory
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)

# Base class for ORM models
Base = declarative_base()


@contextmanager
def get_db_session() -> Generator[Session, None, None]:
    """
    Context manager for database sessions.
    
    Usage:
        with get_db_session() as session:
            result = session.query(TestCase).all()
            # session.commit() called automatically on success
            # session.rollback() called automatically on exception
    
    Yields:
        Session: SQLAlchemy database session
    """
    session = SessionLocal()
    try:
        yield session
        session.commit()
    except Exception:
        session.rollback()
        raise
    finally:
        session.close()


def init_db():
    """Initialize database (create all tables from models)."""
    Base.metadata.create_all(bind=engine)


def drop_db():
    """Drop all tables (use with caution!)."""
    Base.metadata.drop_all(bind=engine)


def get_session() -> Session:
    """
    Get a new database session (manual management).
    
    Note: Prefer using get_db_session() context manager for automatic cleanup.
    
    Returns:
        Session: SQLAlchemy session (caller must close)
    """
    return SessionLocal()


@event.listens_for(Engine, "connect")
def set_postgresql_pragma(dbapi_conn, connection_record):
    """Set PostgreSQL-specific settings on connect."""
    # Can add PostgreSQL-specific settings here if needed
    pass
```

---

#### 3.2 ORM Model Implementation ‚úÖ

**Status**: ‚úÖ COMPLETED  
**Estimated Hours**: 6h  
**Actual Hours**: [Your actual time]

**Tasks Completed**:
- [x] **T3.2.1**: Created TestCase model (CRITICAL: uses `test_cases` table)
- [x] **T3.2.2**: Created ModelRun model
- [x] **T3.2.3**: Created Response model
- [x] **T3.2.4**: Created Evaluation model
- [x] **T3.2.5**: Defined relationships between models with cascades

**Final Code** (`ml_eval/database/models.py`):

```python
"""SQLAlchemy ORM models for universal ML evaluation framework."""

from datetime import datetime
from typing import List, Optional

from sqlalchemy import (
    Column, Integer, String, Text, Float, Boolean, 
    TIMESTAMP, ForeignKey, ARRAY, CheckConstraint, Index
)
from sqlalchemy.dialects.postgresql import JSONB
from sqlalchemy.orm import relationship

from .connection import Base


class TestCase(Base):
    """
    Universal test case supporting all ML domains.
    
    Stores inputs and expected outputs (ground truth) in flexible JSONB format.
    USER-FIRST PHILOSOPHY: origin='human' by default, is_verified=TRUE by default.
    """
    
    __tablename__ = "test_cases"
    
    # Primary key
    id = Column(Integer, primary_key=True, index=True)
    
    # Flexible input storage (JSONB)
    input_data = Column(JSONB, nullable=False)
    input_type = Column(String(50), nullable=False)  # 'text', 'image_path', 'tabular', etc.
    input_format = Column(String(50))                 # 'json', 'base64', 'url', etc.
    
    # Expected output (JSONB)
    ground_truth = Column(JSONB, nullable=False)
    output_type = Column(String(50), nullable=False)  # 'classification', 'regression', etc.
    
    # Organization
    model_type = Column(String(100))                  # 'computer_vision', 'nlp', etc.
    category = Column(String(100))
    tags = Column(ARRAY(String))
    difficulty = Column(String(50))
    
    # USER-FIRST PHILOSOPHY (CRITICAL)
    origin = Column(String(50), nullable=False, default='human', server_default='human')
    is_verified = Column(Boolean, nullable=False, default=True, server_default='true')
    
    # Metadata
    metadata = Column(JSONB, default={}, server_default='{}')
    created_by = Column(String(255))
    created_at = Column(TIMESTAMP, default=datetime.utcnow, server_default='CURRENT_TIMESTAMP')
    updated_at = Column(TIMESTAMP, default=datetime.utcnow, onupdate=datetime.utcnow, 
                       server_default='CURRENT_TIMESTAMP')
    
    # Relationships
    responses = relationship("Response", back_populates="test_case", cascade="all, delete-orphan")
    
    # Constraints
    __table_args__ = (
        CheckConstraint("input_data IS NOT NULL", name="check_input_not_empty"),
        CheckConstraint("ground_truth IS NOT NULL", name="check_ground_truth_not_empty"),
        CheckConstraint("origin IN ('human', 'ai-generated')", name="check_origin"),
        Index('idx_test_cases_model_type', 'model_type'),
        Index('idx_test_cases_category', 'category'),
        Index('idx_test_cases_origin', 'origin'),
        Index('idx_test_cases_input_data_gin', 'input_data', postgresql_using='gin'),
        Index('idx_test_cases_ground_truth_gin', 'ground_truth', postgresql_using='gin'),
    )
    
    def __repr__(self):
        return (f"<TestCase(id={self.id}, model_type={self.model_type}, "
                f"category={self.category}, origin={self.origin})>")


class ModelRun(Base):
    """
    Model evaluation run tracking.
    
    Tracks execution of test cases against a specific model version.
    """
    
    __tablename__ = "model_runs"
    
    id = Column(Integer, primary_key=True, index=True)
    model_name = Column(String(255), nullable=False)
    model_version = Column(String(100), nullable=False)
    model_type = Column(String(100), nullable=False)  # 'computer_vision', 'nlp', etc.
    model_endpoint = Column(Text)                      # API URL or local path
    config = Column(JSONB, default={}, server_default='{}')
    status = Column(String(50), nullable=False, default="pending", server_default="pending")
    started_at = Column(TIMESTAMP, default=datetime.utcnow, server_default='CURRENT_TIMESTAMP')
    completed_at = Column(TIMESTAMP)
    total_cases = Column(Integer, default=0, server_default='0')
    completed_cases = Column(Integer, default=0, server_default='0')
    failed_cases = Column(Integer, default=0, server_default='0')
    
    # Relationships
    responses = relationship("Response", back_populates="run", cascade="all, delete-orphan")
    
    # Constraints
    __table_args__ = (
        CheckConstraint(
            "status IN ('pending', 'running', 'completed', 'failed', 'cancelled')",
            name="check_status"
        ),
        CheckConstraint(
            "total_cases >= 0 AND completed_cases >= 0 AND failed_cases